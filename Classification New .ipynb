{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import openml\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from progressbar import ProgressBar\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all datatsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>name</th>\n",
       "      <th>version</th>\n",
       "      <th>uploader</th>\n",
       "      <th>status</th>\n",
       "      <th>format</th>\n",
       "      <th>MajorityClassSize</th>\n",
       "      <th>MaxNominalAttDistinctValues</th>\n",
       "      <th>MinorityClassSize</th>\n",
       "      <th>NumberOfClasses</th>\n",
       "      <th>NumberOfFeatures</th>\n",
       "      <th>NumberOfInstances</th>\n",
       "      <th>NumberOfInstancesWithMissingValues</th>\n",
       "      <th>NumberOfMissingValues</th>\n",
       "      <th>NumberOfNumericFeatures</th>\n",
       "      <th>NumberOfSymbolicFeatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>anneal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>684.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>22175.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>kr-vs-kp</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>1669.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3196.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>labor</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>arrhythmia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>245.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>letter</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>813.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>audiology</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>57.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>liver-disorders</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>autos</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>67.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>lymph</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>balance-scale</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>active</td>\n",
       "      <td>ARFF</td>\n",
       "      <td>288.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    did             name  version uploader  status format  MajorityClassSize  \\\n",
       "2     2           anneal        1        1  active   ARFF              684.0   \n",
       "3     3         kr-vs-kp        1        1  active   ARFF             1669.0   \n",
       "4     4            labor        1        1  active   ARFF               37.0   \n",
       "5     5       arrhythmia        1        1  active   ARFF              245.0   \n",
       "6     6           letter        1        1  active   ARFF              813.0   \n",
       "7     7        audiology        1        1  active   ARFF               57.0   \n",
       "8     8  liver-disorders        1        1  active   ARFF                NaN   \n",
       "9     9            autos        1        1  active   ARFF               67.0   \n",
       "10   10            lymph        1        1  active   ARFF               81.0   \n",
       "11   11    balance-scale        1        1  active   ARFF              288.0   \n",
       "\n",
       "    MaxNominalAttDistinctValues  MinorityClassSize  NumberOfClasses  \\\n",
       "2                           7.0                8.0              5.0   \n",
       "3                           3.0             1527.0              2.0   \n",
       "4                           3.0               20.0              2.0   \n",
       "5                          13.0                2.0             13.0   \n",
       "6                          26.0              734.0             26.0   \n",
       "7                          24.0                1.0             24.0   \n",
       "8                           NaN                NaN              0.0   \n",
       "9                          22.0                3.0              6.0   \n",
       "10                          8.0                2.0              4.0   \n",
       "11                          3.0               49.0              3.0   \n",
       "\n",
       "    NumberOfFeatures  NumberOfInstances  NumberOfInstancesWithMissingValues  \\\n",
       "2               39.0              898.0                               898.0   \n",
       "3               37.0             3196.0                                 0.0   \n",
       "4               17.0               57.0                                56.0   \n",
       "5              280.0              452.0                               384.0   \n",
       "6               17.0            20000.0                                 0.0   \n",
       "7               70.0              226.0                               222.0   \n",
       "8                6.0              345.0                                 0.0   \n",
       "9               26.0              205.0                                46.0   \n",
       "10              19.0              148.0                                 0.0   \n",
       "11               5.0              625.0                                 0.0   \n",
       "\n",
       "    NumberOfMissingValues  NumberOfNumericFeatures  NumberOfSymbolicFeatures  \n",
       "2                 22175.0                      6.0                      33.0  \n",
       "3                     0.0                      0.0                      37.0  \n",
       "4                   326.0                      8.0                       9.0  \n",
       "5                   408.0                    206.0                      74.0  \n",
       "6                     0.0                     16.0                       1.0  \n",
       "7                   317.0                      0.0                      70.0  \n",
       "8                     0.0                      6.0                       0.0  \n",
       "9                    59.0                     15.0                      11.0  \n",
       "10                    0.0                      3.0                      16.0  \n",
       "11                    0.0                      4.0                       1.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_df = openml.datasets.list_datasets(output_format=\"dataframe\")\n",
    "datasets_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dataset = openml.datasets.get_dataset(294)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print description about dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is dataset 'satellite_image', the target feature is 'class'\n",
      "URL: https://www.openml.org/data/v1/download/50720/satellite_image.arff\n",
      "**Author**:   \n",
      "**Source**: Unknown - 1993  \n",
      "**Please cite**:   \n",
      "\n",
      "Source:\n",
      "Ashwin Srinivasan\n",
      "Department of Statistics and Data Modeling\n",
      "University of Strathclyde\n",
      "Glasgow\n",
      "Scotland\n",
      "UK\n",
      "ross '@' uk.ac.turing\n",
      "\n",
      "The original Landsat data for this database was generated from data purchased from NASA by the Australian Centre for Remote Sensing, and used for research at: \n",
      "The Centre for Remote Sensing\n",
      "University of New South Wales\n",
      "Kensington, PO Box 1\n",
      "NSW 2033\n",
      "Australia.\n",
      "\n",
      "The sample database was generated taking a small section (82 rows and 100 columns) from the original data. The binary values were converted to their present ASCII form by Ashwin Srinivasan. The classification for each pixel was performed on the basis of an actual site visit by Ms. Karen Hall, when working for Professor John A. Richards, at the Centre for Remote Sensing at the University of New South Wales, Australia. Conversion to 3x3 neighbourhoods and splitting into test and training sets was done by Alistair Sutherland.\n",
      "\n",
      "Data Set Information:\n",
      "The database consists of the multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhood. The aim is to predict this classification, given the multi-spectral values. In the sample database, the class of a pixel is coded as a number. The Landsat satellite data is one of the many sources of information available for a scene. The interpretation of a scene by  integrating spatial data of diverse types and resolutions including multispectral and radar data, maps indicating topography, land use etc. is expected to assume significant importance with the onset of an era characterised by integrative approaches to remote sensing (for example, NASA's Earth Observing System commencing this decade). Existing statistical methods are ill-equipped for handling such diverse data types. Note that this is not true for Landsat MSS data considered in isolation (as in this sample database). This data satisfies the important requirements of being numerical and at a single resolution, and standard maximum-likelihood classification performs very well. Consequently, for this data, it should be interesting to compare the performance of other methods against the statistical approach. One frame of Landsat MSS imagery consists of four digital images of the same scene in different spectral bands. Two of these are in the visible region (corresponding approximately to green and red regions of the visible spectrum) and two are in the (near) infra-red. Each pixel is a 8-bit binary word, with 0 corresponding to black and 255 to white. The spatial resolution of a pixel is about 80m x 80m. Each image contains 2340 x 3380 such pixels. The database is a (tiny) sub-area of a scene, consisting of 82 x 100 pixels. Each line of data corresponds to a 3x3 square neighbourhood of pixels completely contained within the 82x100 sub-area. Each line contains the pixel values in the four spectral bands (converted to ASCII) of each of the 9 pixels in the 3x3 neighbourhood and a number indicating the classification label of the central pixel. The number is a code for the following classes:\n",
      "\n",
      "Number Class\n",
      "1 red soil\n",
      "2 cotton crop\n",
      "3 grey soil\n",
      "4 damp grey soil\n",
      "5 soil with vegetation stubble\n",
      "6 mixture class (all types present)\n",
      "7 very damp grey soil\n",
      "NB. There are no examples with class 6 in this dataset.\n",
      " \n",
      "The data is given in random order and certain lines of data have been removed so you cannot reconstruct the original image from this dataset. In each line of data the four spectral values for the top-left pixel are given first followed by the four spectral values for the top-middle pixel and then those for the top-right pixel, and so on with the pixels read out in sequence left-to-right and top-to-bottom. Thus, the four spectral values for the central pixel are given by attributes 17,18,19 and 20. If you like you can use only these four attributes, while ignoring the others. This avoids the problem which arises when a 3x3 neighbourhood straddles a boundary.\n",
      "\n",
      "Attribute Information:\n",
      "The attributes are numerical, in the range 0 to 255.\n",
      "\n",
      "UCI: http://archive.ics.uci.edu/ml/datasets/Statlog+(Landsat+Satellite)\n"
     ]
    }
   ],
   "source": [
    "# Print a summary\n",
    "print(\n",
    "    f\"This is dataset '{dataset.name}', the target feature is \"\n",
    "    f\"'{dataset.default_target_attribute}'\"\n",
    ")\n",
    "print(f\"URL: {dataset.url}\")\n",
    "print(dataset.description[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get depent and indepent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "    dataset_format=\"dataframe\", target=dataset.default_target_attribute\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attr1     uint8\n",
       "attr2     uint8\n",
       "attr3     uint8\n",
       "attr4     uint8\n",
       "attr5     uint8\n",
       "attr6     uint8\n",
       "attr7     uint8\n",
       "attr8     uint8\n",
       "attr9     uint8\n",
       "attr10    uint8\n",
       "attr11    uint8\n",
       "attr12    uint8\n",
       "attr13    uint8\n",
       "attr14    uint8\n",
       "attr15    uint8\n",
       "attr16    uint8\n",
       "attr17    uint8\n",
       "attr18    uint8\n",
       "attr19    uint8\n",
       "attr20    uint8\n",
       "attr21    uint8\n",
       "attr22    uint8\n",
       "attr23    uint8\n",
       "attr24    uint8\n",
       "attr25    uint8\n",
       "attr26    uint8\n",
       "attr27    uint8\n",
       "attr28    uint8\n",
       "attr29    uint8\n",
       "attr30    uint8\n",
       "attr31    uint8\n",
       "attr32    uint8\n",
       "attr33    uint8\n",
       "attr34    uint8\n",
       "attr35    uint8\n",
       "attr36    uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# cat_columns = x.select_dtypes(['category']).columns\n",
    "# x[cat_columns] = x[cat_columns].apply(lambda x: pd.factorize(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attr1     uint8\n",
       "attr2     uint8\n",
       "attr3     uint8\n",
       "attr4     uint8\n",
       "attr5     uint8\n",
       "attr6     uint8\n",
       "attr7     uint8\n",
       "attr8     uint8\n",
       "attr9     uint8\n",
       "attr10    uint8\n",
       "attr11    uint8\n",
       "attr12    uint8\n",
       "attr13    uint8\n",
       "attr14    uint8\n",
       "attr15    uint8\n",
       "attr16    uint8\n",
       "attr17    uint8\n",
       "attr18    uint8\n",
       "attr19    uint8\n",
       "attr20    uint8\n",
       "attr21    uint8\n",
       "attr22    uint8\n",
       "attr23    uint8\n",
       "attr24    uint8\n",
       "attr25    uint8\n",
       "attr26    uint8\n",
       "attr27    uint8\n",
       "attr28    uint8\n",
       "attr29    uint8\n",
       "attr30    uint8\n",
       "attr31    uint8\n",
       "attr32    uint8\n",
       "attr33    uint8\n",
       "attr34    uint8\n",
       "attr35    uint8\n",
       "attr36    uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change response variable to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       3\n",
       "2       3\n",
       "3       3\n",
       "4       3\n",
       "       ..\n",
       "6430    1\n",
       "6431    1\n",
       "6432    5\n",
       "6433    5\n",
       "6434    5\n",
       "Name: class, Length: 6435, dtype: uint8"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y=y.map({'1' :0,'2':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       3\n",
       "2       3\n",
       "3       3\n",
       "4       3\n",
       "       ..\n",
       "6430    1\n",
       "6431    1\n",
       "6432    5\n",
       "6433    5\n",
       "6434    5\n",
       "Name: class, Length: 6435, dtype: int32"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         attr1     attr2     attr3     attr4     attr5     attr6     attr7  \\\n",
      "0     0.815385  0.800000  0.770115  0.504132  0.692308  0.681818  0.589474   \n",
      "1     0.692308  0.681818  0.609195  0.380165  0.692308  0.681818  0.547368   \n",
      "2     0.692308  0.681818  0.563218  0.413223  0.630769  0.681818  0.547368   \n",
      "3     0.630769  0.681818  0.563218  0.380165  0.692308  0.609091  0.547368   \n",
      "4     0.692308  0.609091  0.563218  0.380165  0.630769  0.609091  0.505263   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "6430  0.323077  0.509091  0.494253  0.429752  0.384615  0.545455  0.526316   \n",
      "6431  0.384615  0.472727  0.540230  0.429752  0.261538  0.400000  0.484211   \n",
      "6432  0.261538  0.372727  0.436782  0.396694  0.261538  0.336364  0.431579   \n",
      "6433  0.261538  0.372727  0.390805  0.338843  0.323077  0.400000  0.431579   \n",
      "6434  0.323077  0.400000  0.436782  0.396694  0.323077  0.336364  0.568421   \n",
      "\n",
      "         attr8     attr9    attr10  ...    attr27  attr28    attr29    attr30  \\\n",
      "0     0.390625  0.687500  0.728155  ...  0.933333   0.600  0.753846  0.912621   \n",
      "1     0.421875  0.625000  0.728155  ...  0.866667   0.568  0.692308  0.776699   \n",
      "2     0.390625  0.687500  0.650485  ...  0.700000   0.464  0.692308  0.699029   \n",
      "3     0.390625  0.625000  0.650485  ...  0.600000   0.400  0.692308  0.699029   \n",
      "4     0.367188  0.625000  0.728155  ...  0.600000   0.400  0.692308  0.737864   \n",
      "...        ...       ...       ...  ...       ...     ...       ...       ...   \n",
      "6430  0.460938  0.375000  0.543689  ...  0.600000   0.504  0.415385  0.582524   \n",
      "6431  0.437500  0.250000  0.398058  ...  0.555556   0.448  0.415385  0.543689   \n",
      "6432  0.406250  0.203125  0.359223  ...  0.555556   0.416  0.307692  0.582524   \n",
      "6433  0.406250  0.312500  0.359223  ...  0.511111   0.360  0.307692  0.543689   \n",
      "6434  0.546875  0.250000  0.359223  ...  0.466667   0.360  0.307692  0.543689   \n",
      "\n",
      "        attr31    attr32    attr33    attr34    attr35    attr36  \n",
      "0     0.821053  0.554688  0.692308  0.776699  0.663158  0.453125  \n",
      "1     0.663158  0.453125  0.692308  0.699029  0.568421  0.390625  \n",
      "2     0.568421  0.390625  0.692308  0.699029  0.568421  0.390625  \n",
      "3     0.568421  0.390625  0.692308  0.737864  0.568421  0.390625  \n",
      "4     0.568421  0.390625  0.615385  0.776699  0.621053  0.453125  \n",
      "...        ...       ...       ...       ...       ...       ...  \n",
      "6430  0.610526  0.468750  0.369231  0.543689  0.568421  0.437500  \n",
      "6431  0.526316  0.437500  0.369231  0.543689  0.526316  0.406250  \n",
      "6432  0.484211  0.406250  0.369231  0.543689  0.442105  0.351562  \n",
      "6433  0.442105  0.351562  0.307692  0.543689  0.442105  0.320312  \n",
      "6434  0.442105  0.320312  0.369231  0.504854  0.610526  0.492188  \n",
      "\n",
      "[6435 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "df_min_max_scaled = x.copy()\n",
    "  \n",
    "# apply normalization techniques\n",
    "for column in df_min_max_scaled.columns:\n",
    "    df_min_max_scaled[column] = (df_min_max_scaled[column] - df_min_max_scaled[column].min()) / (df_min_max_scaled[column].max() - df_min_max_scaled[column].min())    \n",
    "  \n",
    "# view normalized data\n",
    "print(df_min_max_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pbar = ProgressBar()\n",
    "x=df_min_max_scaled.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81538462, 0.8       , 0.77011494, ..., 0.77669903, 0.66315789,\n",
       "        0.453125  ],\n",
       "       [0.69230769, 0.68181818, 0.6091954 , ..., 0.69902913, 0.56842105,\n",
       "        0.390625  ],\n",
       "       [0.69230769, 0.68181818, 0.56321839, ..., 0.69902913, 0.56842105,\n",
       "        0.390625  ],\n",
       "       ...,\n",
       "       [0.26153846, 0.37272727, 0.43678161, ..., 0.54368932, 0.44210526,\n",
       "        0.3515625 ],\n",
       "       [0.26153846, 0.37272727, 0.3908046 , ..., 0.54368932, 0.44210526,\n",
       "        0.3203125 ],\n",
       "       [0.32307692, 0.4       , 0.43678161, ..., 0.50485437, 0.61052632,\n",
       "        0.4921875 ]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "DatasetName='Satelite.json'\n",
    "cross=\"Satelite_cross.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search cv function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridfun(fName,x,y,estimator,param_grid,DatasetName):\n",
    "    for i in range(1,11):\n",
    "        cross_validation = StratifiedKFold(n_splits=5, shuffle=True, random_state=i)\n",
    "        grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=cross_validation, scoring=f1,n_jobs=8)\n",
    "        start = time.time()\n",
    "        grid_result = grid_search.fit(x,y)\n",
    "        end = time.time()\n",
    "        knn_time=end-start\n",
    "        random_state=i\n",
    "        Knn_Para=grid_result.best_params_\n",
    "        Knn_f1_score=grid_result.best_score_\n",
    "        \n",
    "        details = {\n",
    "            'Random State':random_state,\n",
    "            'name': fName,\n",
    "            'time': knn_time,\n",
    "            'f1_score':Knn_f1_score,\n",
    "            'Best_Parameter':Knn_Para,\n",
    "            \n",
    "            \n",
    "    \n",
    "        }\n",
    "        with open(DatasetName, 'a') as json_file:\n",
    "            json.dump(details, json_file)\n",
    "            json_file.write('\\n')\n",
    "     \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increment ,function random state, time, best parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier()\n",
    "f1 = make_scorer(f1_score , average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "start = time.time()\n",
    "cross_val_score_knn=cross_val_score(knn,x,y,cv=5,scoring=f1).mean()\n",
    "end = time.time()\n",
    "knn_time=end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cross_validation = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "n_neighbors = range(1, 21)\n",
    "weights = ['uniform', 'distance']\n",
    "metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n",
    "\n",
    "gridfun(\"KNN\",x,y,model,grid,DatasetName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf = LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "start = time.time()\n",
    "cross_val_score_linear=cross_val_score(knn,x,y,cv=5,scoring=f1).mean()\n",
    "end = time.time()\n",
    "Linear_dis_time=end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cross_validation = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "solver = ['svd', 'lsqr', 'eigen']\n",
    "grid = dict(solver=solver)\n",
    "\n",
    "gridfun(\"KNN\",x,y,model,grid,DatasetName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb=GaussianNB()\n",
    "f1 = make_scorer(f1_score , average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "nb.priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "start = time.time()\n",
    "cross_val_score_naive=cross_val_score(nb,x,y,cv=5,scoring=f1).mean()\n",
    "end = time.time()\n",
    "Naive_time=end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cross_validation = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "model = GaussianNB()\n",
    "\n",
    "\n",
    "var_smoothing = [1e-09,2e-09,3e-09,4e-09,5e-09,6e-09,7e-09,8e-09,9e-09,10e-09]\n",
    "\n",
    "grid = dict(var_smoothing=var_smoothing)\n",
    "\n",
    "gridfun(\"Naive\",x,y,model,grid,DatasetName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm=SVC()\n",
    "f1 = make_scorer(f1_score , average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "start = time.time()\n",
    "cross_val_score_support=cross_val_score(svm,x,y,cv=5,scoring=f1).mean()\n",
    "end = time.time()\n",
    "Support_time=end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cross_validation = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "model = SVC()\n",
    "\n",
    "c = range(1, 20, 1)\n",
    "kernel = ['poly', 'rbf', 'sigmoid']\n",
    "gamma = ['scale', 'auto']\n",
    "grid = dict(C=c,kernel=kernel,gamma=gamma)\n",
    "\n",
    "gridfun(\"Support\",x,y,model,grid,DatasetName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=1)\n",
    "f1 = make_scorer(f1_score , average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "start = time.time()\n",
    "cross_val_score_Logistic=cross_val_score(svm,x,y,cv=5,scoring=f1).mean()\n",
    "\n",
    "end = time.time()\n",
    "logistic_time=end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "cross_validation = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "model = LogisticRegression()\n",
    "\n",
    "# dual = ['bool','False']\n",
    "penalty = [ 'l2']\n",
    "# class_weight = ['dict', 'balanced']\n",
    "grid = dict(penalty=penalty)\n",
    "\n",
    "gridfun(\"Logistic\",x,y,model,grid,DatasetName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "f1 = make_scorer(f1_score , average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "start = time.time()\n",
    "cross_val_score_random=cross_val_score(rf,x,y,cv=5,scoring=f1).mean()\n",
    "\n",
    "end = time.time()\n",
    "random_time=end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cross_validation = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "model=RandomForestClassifier()\n",
    "\n",
    "n_estimators = range(1, 20, 1)\n",
    "criterion = ['gini', 'entropy']\n",
    "grid = dict(n_estimators=n_estimators,criterion=criterion)\n",
    "\n",
    "gridfun(\"Random\",x,y,model,grid,DatasetName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "f1 = make_scorer(f1_score , average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "start = time.time()\n",
    "cross_val_score_Adaboost=cross_val_score(clf,x,y,cv=5,scoring=f1).mean()\n",
    "end = time.time()\n",
    "Adaboost_time=end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cross_validation = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "n_estimators = range(1, 100, 1)\n",
    "algorithm = ['SAMME', 'SAMME.R']\n",
    "grid = dict(n_estimators=n_estimators,algorithm=algorithm)\n",
    "\n",
    "gridfun(\"Ada boost\",x,y,model,grid,DatasetName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=2, random_state=0)\n",
    "f1 = make_scorer(f1_score , average='macro')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "start = time.time()\n",
    "cross_val_score_gradient=cross_val_score(clf,x,y,cv=5,scoring=f1).mean()\n",
    "end = time.time()\n",
    "gradient_time=end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cross_validation = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "model=GradientBoostingClassifier()\n",
    "\n",
    "max_depth=range(1, 10, 1)\n",
    "n_estimators=[100]\n",
    "# learning_rate =np.arange(0.05, 0.2, 0.05)\n",
    "learning_rate=[0.01]\n",
    "grid = dict(n_estimators=n_estimators,max_depth=max_depth,learning_rate=learning_rate)\n",
    "\n",
    "gridfun(\"Gradient\",x,y,model,grid,DatasetName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "gb_clf = xgb.XGBClassifier(eta=0.3,gamma=0,max_depth=6)\n",
    "f1 = make_scorer(f1_score , average='macro')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:50:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:50:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:50:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:50:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:50:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "start = time.time()\n",
    "cross_val_score_xgboost=cross_val_score(gb_clf,x,y,cv=5,scoring=f1).mean()\n",
    "end = time.time()\n",
    "xgboost_time=end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:00:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:10:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:20:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:30:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:40:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:50:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:00:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:10:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uc file\\intern ship\\projects\\quarterly_median_rents-analysis-\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:20:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "cross_validation = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "model=xgb.XGBClassifier()\n",
    "\n",
    "gamma=range(1, 10, 1)\n",
    "eta=[0.001,0.01,0.05]\n",
    "grid = dict(eta=eta,gamma=gamma)\n",
    "\n",
    "gridfun(\"XGBoost\",x,y,model,grid,DatasetName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# save all croos validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "details = {\n",
    "    'Knn':cross_val_score_knn ,\n",
    "    'Linear': cross_val_score_linear,\n",
    "    'Naive':cross_val_score_naive,\n",
    "    'support':cross_val_score_support,\n",
    "    'Logistic':cross_val_score_Logistic,\n",
    "    'Random':cross_val_score_random,\n",
    "    'Ada boost':cross_val_score_Adaboost,\n",
    "    'Gradient':cross_val_score_gradient,\n",
    "    'XG Boost':cross_val_score_xgboost,\n",
    "    \n",
    "    \n",
    "}\n",
    "with open(cross, 'a') as json_file:\n",
    "    json.dump(details, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}